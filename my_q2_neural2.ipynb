{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "from my_q1_softmax import softmax\n",
    "from my_q2_sigmoid import sigmoid, sigmoid_grad\n",
    "from my_q2_gradcheck import gradcheck_naive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.stats import logistic\n",
    "def forward_backprop(data, labels, params, dimensions):\n",
    "    ofs = 0\n",
    "    Dx, H, Dy = (dimensions[0], dimensions[1], dimensions[2])\n",
    "\n",
    "    W1 = np.reshape(params[ofs:ofs+ Dx * H], (Dx, H))\n",
    "    ofs += Dx * H\n",
    "    b1 = np.reshape(params[ofs:ofs + H], (1, H))\n",
    "    ofs += H\n",
    "    W2 = np.reshape(params[ofs:ofs + H * Dy], (H, Dy))\n",
    "    ofs += H * Dy\n",
    "    b2 = np.reshape(params[ofs:ofs + Dy], (1, Dy))\n",
    "    h=sigmoid(np.dot(data,W1)+b1)\n",
    "    y_pred=softmax(np.dot(h,W2)+b2)\n",
    "\n",
    "    # Back-Propagation\n",
    "    gradtheta=y_pred-labels\n",
    "    gradW2=np.dot(h.T,gradtheta)\n",
    "    gradb2=y_pred-labels\n",
    "    gradh=np.dot(gradtheta,W2.T)\n",
    "    #gradsigmoid=np.multiply(gradh,sigmoid_grad(np.dot(data,W1)+b1)) \n",
    "    gradsigmoid=np.multiply(gradh,logistic._pdf(np.dot(data,W1)+b1)) \n",
    "    gradW1=np.dot(data.T,gradsigmoid)\n",
    "    gradb1=gradsigmoid\n",
    "    ### Stack gradients (do not modify)\n",
    "    ### Has been Modified with a transpose and axis\n",
    "    grad = np.concatenate((gradW1.flatten(), gradb1.flatten(), gradW2.flatten(), gradb2.flatten()),axis=1).T\n",
    "    cost=-np.dot(labels,np.log(y_pred).T)[0,0]\n",
    "    return cost, grad.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(115L,)\n",
      "5.43450655877\n",
      "4.77565556959\n",
      "4.20127705162\n",
      "(115L,)\n",
      "1.66281492482\n",
      "1.14962211471\n",
      "0.81196500196\n",
      "(115L,)\n",
      "2.48534465306\n",
      "1.56707659553\n",
      "0.953691182306\n",
      "(115L,)\n",
      "2.95393387306\n",
      "2.38649972918\n",
      "1.9064523641\n",
      "(115L,)\n",
      "3.47824084049\n",
      "2.68877543459\n",
      "2.01375090017\n",
      "(115L,)\n",
      "4.79790724906\n",
      "3.49963860429\n",
      "2.48263234369\n",
      "(115L,)\n",
      "3.25609074354\n",
      "2.78474915346\n",
      "2.47191229228\n",
      "(115L,)\n",
      "3.3037284478\n",
      "2.61306290471\n",
      "2.21288326252\n",
      "(115L,)\n",
      "3.47329601212\n",
      "2.41153637518\n",
      "1.53539229708\n",
      "(115L,)\n",
      "2.26403613219\n",
      "1.65373572828\n",
      "1.20011851691\n"
     ]
    }
   ],
   "source": [
    "N = 10\n",
    "dimensions = [10, 5, 10]\n",
    "data2 = np.random.randn(N, dimensions[0])   # each row will be a datum\n",
    "\n",
    "labels2 = np.zeros((N, dimensions[2]))\n",
    "for i in xrange(N):\n",
    "    labels2[i,random.randint(0,dimensions[2]-1)] = 1\n",
    "for j in range(N):\n",
    "    data=np.matrix(data2[0])    \n",
    "    labels=np.matrix(labels2[0])\n",
    "    params = np.random.randn((dimensions[0] + 1) * dimensions[1] + (\n",
    "    dimensions[1] + 1) * dimensions[2], )\n",
    "    print params.shape\n",
    "    params\n",
    "    for count in xrange(3):\n",
    "        cost, grad=forward_backprop(data, labels, params, dimensions)\n",
    "        my_gradcheck_new(forward_backprop,data, labels, params, dimensions)    \n",
    "        print cost\n",
    "        grad=grad.flatten()\n",
    "        for j in xrange(len(params)):\n",
    "            params[j]=params[j]-(alpha*grad[0,j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def my_gradcheck_new(lossfunction,data, labels, params, dimensions):\n",
    "    count=0\n",
    "    it = np.nditer(params, flags=['multi_index'], op_flags=['readwrite'])\n",
    "    eps=1e-5 \n",
    "    while not it.finished:\n",
    "        ix = it.multi_index\n",
    "        params2=params\n",
    "        params2[ix]=params[ix]+eps\n",
    "        cost1=lossfunction(data, labels, params2, dimensions)\n",
    "        params2[ix]=params[ix]-eps\n",
    "        cost2=lossfunction(data, labels, params2, dimensions)\n",
    "        numgrad=(cost1[0]-cost2[0])/(eps)\n",
    "        reldiff = abs(numgrad - grad[0,ix]) / max(1, abs(numgrad), abs(grad[0,ix]))\n",
    "        #print reldiff\n",
    "        if reldiff > 1e-4:\n",
    "            count+=1\n",
    "            print \"First gradient error found at index %s\" % str(ix)\n",
    "            print \"Relative Difference is %f\" %reldiff\n",
    "            print \"Your gradient: %f \\t Numerical gradient: %f\" % (grad[0,ix], numgrad)\n",
    "        it.iternext() # Step to next dimension\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count 0\n"
     ]
    }
   ],
   "source": [
    "my_gradcheck_new(forward_backprop,data, labels, params, dimensions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.37927885 -0.51994342  1.20641448 -1.21785846  0.44703048  1.30024322\n",
      " -0.32617239  0.97650261 -0.04435326 -0.09955904]\n"
     ]
    }
   ],
   "source": [
    "print data[0]"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
